<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Towards unconstrained joint hand-object reconstruction from RGB videos">
    <meta name="author" content="WILLOW team">

    <title>Towards unconstrained joint hand-object reconstruction from RGB videos</title>

    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">

  </head>

  <body>

  <div class="container">
      <div class="header">
        <h3> <center> <b>Towards unconstrained joint hand-object reconstruction from RGB videos</b> </center> </h3>
      </div>

      <center>
	      <img src="homanimages/5900_in.gif" title="" style="max-width:25%;vertical-align:top" /> 
        <img src="homanimages/0011.gif" title="" style="max-width:25%;vertical-align:top" /> 
         <img src="homanimages/5900_cam.gif" title="" style="max-width:25%;vertical-align:top" /> 
      </center>

      <div class="row">
        <h3>People</h3>
        <center>
                <table style="width:70%">
                <tr>
			<td><a href="https://hassony2.github.io"><img id="image" src="photos/yana.png" width="60"></img> <br/> Yana <br /> Hasson</a></td>
      <td><a href="http://www.di.ens.fr/~varol/"><img id="image" src="photos/gul.jpg" width="60"></img> <br/> G&uuml;l <br />Varol</a></td>
			<td><a href="http://www.di.ens.fr/~laptev/"><img id="image" src="photos/ivan.jpg" width="60"></img> <br/> Ivan <br />Laptev</a></td>
			<td><a href="http://lear.inrialpes.fr/~schmid/"><img id="image" src="photos/cordelia.jpg" width="60"></img> <br/>Cordelia <br />Schmid</a></td>
                </tr>
                </table>
        </center>
      </div>

      <div class="row">
        <h3>Abstract</h3>
        <p style="text-align: justify;">
Our work aims to obtain 3D reconstruction of hands and manipulated objects from monocular videos. 
Reconstructing hand-object manipulations holds a great potential for robotics and learning from human demonstrations.
The supervised  learning  approach  to  this  problem,  however,  requires 3D supervision and remains limited to constrained laboratory  settings  and  simulators  for  which  3D  ground truth is available.
In this paper we first propose a learning-free fitting approach for hand-object reconstruction  which can seamlessly handle two-hand object interactions.
Our method relies  on  cues  obtained  with  common  methods  for  object detection, hand pose estimation and instance segmentation. 
We quantitatively evaluate our approach and show that it can be applied to datasets with varying levels of difficulty for which training data is unavailable.
        </p>
	</div>
      <div class="row">
      <h3>Paper </h3>

  <ul class="list" style="list-style-type:square">
    <li><a href="http://arxiv.org/abs/2108.07044">Paper</a></li>
  </ul>

      <h3> Code </h3>

  <ul class="list" style="list-style-type:square">
	  <li><a href="https://github.com/hassony2/homan"> Code </a></li>
    </ul>
	      

    	If you find this work interesting, you will be no doubt interested by the following publication:
        <a href="https://people.eecs.berkeley.edu/~zhecao/rhoi/">Reconstructing Hand-Object Interactions in the Wild</a>, Cao et al., ICCV 2021
<!--
    <li><a href="bodynet_poster.pdf">Poster</a></li>
    <li><a href="bodynet_presentation.pdf">Presentation</a></li>
-->
    
      <h4>BibTeX</h4>
                  <pre><tt>@INPROCEEDINGS{hasson20_handobjectconsist,
  title &nbsp&nbsp&nbsp&nbsp= {Towards unconstrained joint hand-object reconstruction from RGB videos},
  author &nbsp&nbsp = {Hasson, Yana  and Varol, G{\"u}l and Laptev, Ivan and Schmid, Cordelia},
  booktitle = {ArXiv},
  year &nbsp&nbsp&nbsp&nbsp&nbsp= {2021}
}</tt></pre>
      </div>
      <!--
    <div class="row">
    <h3> Video </h3>
    <center>
	    <video width="780" height="440" controls>
  <source src="videos/ObMan.webm" type='video/webm'>
</video>
</center>
      </div>

-->
      <div class="row">
        <h3>Acknowledgements</h3>
        <p>
        This work was funded in part by the MSR-Inria joint lab, the French government
        under management of Agence Nationale de la Recherche as
        part of the ”Investissements d’avenir” program, reference
        ANR19-P3IA-0001 (PRAIRIE 3IA Institute) and by Louis
        Vuitton ENS Chair on Artificial Intelligence.
        <p>
	</p>
       </p>
      </div>
      <div class="row">
        <h3>Copyright Notice</h3>
        <p>The documents contained in these directories are included by the contributing authors as a means to ensure timely dissemination of scholarly and technical work on a non-commercial basis. Copyright and all rights therein are maintained by the authors or by other copyright holders, notwithstanding that they have offered their works here electronically. It is understood that all persons copying this information will adhere to the terms and constraints invoked by each author's copyright.</p>
      </div>

    </div> <!-- /container -->

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
  </body>
</html>
